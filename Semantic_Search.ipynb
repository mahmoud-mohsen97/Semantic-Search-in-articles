{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Before semantic search**, `lexical search` method with word matching was commonly used.\n",
        "\n",
        "Lexical search matches words from the query in the dataset/article to find answers.\n",
        "\n",
        "But `Semantic Search` is a powerful way to search using context where Semantic search considers the actual **meaning** of the sentence.\n",
        "\n",
        "- Semantic search uses text embeddings to map words into numerical representations based on their meaning.\n",
        "- Similar words have similar points in the embedding space, enabling meaningful comparisons."
      ],
      "metadata": {
        "id": "bdHNoC6HirYc"
      },
      "id": "bdHNoC6HirYc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "So in this notebook I'll build a semantic search engine for english articels which is the AI & DS services from [Cyshield website](https://cyshield.com/AIDS)."
      ],
      "metadata": {
        "id": "hgVIw3JV4Rl1"
      },
      "id": "hgVIw3JV4Rl1"
    },
    {
      "cell_type": "markdown",
      "id": "6822588f",
      "metadata": {
        "id": "6822588f"
      },
      "source": [
        "# The article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3c644ca0-e1d2-42e4-a668-12e3c80413ed",
      "metadata": {
        "height": 914,
        "id": "3c644ca0-e1d2-42e4-a668-12e3c80413ed"
      },
      "outputs": [],
      "source": [
        "article = \"\"\"\n",
        "Statistical Modelling and Analysis:\n",
        "At Cyshield, AI is not just a buzzword for us! We know exactly how to realize the full potential of AI to support your business. Our data scientists will quickly build and fine-tune predictive analytics solutions to provide you with actionable insights to take your business to the next level.\n",
        "We will gladly take care of all the complicated infrastructure required to build and maintain AI models so that you can focus on what matters.\n",
        "\n",
        "\n",
        "Big Data:\n",
        "With an ever-increasing amount of data being created every day, specialized big data platforms, pipelines and analysis technique are required to handle storage and analysis of such immense volumes of data.\n",
        "Cyshield big data services to efficiently acquire, transform, and analyze data. Our data scientists and engineers will help you make sense out of big data and provide you with valuable insights that can transform your business.\n",
        "\n",
        "\n",
        "Computer Vision:\n",
        "With the prevalence of cameras and CCTV, computer vision techniques have become indispensable to extract information from visual data. At Cyshield, we build state-of-the-art deep learning models to detect and identify any relevant information from images and videos.\n",
        "Our computer vision applications include:\n",
        "Object detection:\n",
        "detect and identify objects of interest in images and videos.\n",
        "Facial Recognition:\n",
        "Recognize people and facial features in images and videos.\n",
        "Activity recognition:\n",
        "Recognize certain activities from video feeds.\n",
        "\n",
        "\n",
        "Natural Language Processing:\n",
        "Natural language processing (NLP) is one of the hottest topics in AI right now, and rightly so since it allows AI-enabled products to understand people and interact with them.\n",
        "Cyshield offers state-of-the-art NLP solutions in various languages for the following applications:\n",
        "Chatbots:\n",
        "Deploy automated chatbot that can understand your users and respond to them in a natural way.\n",
        "Machine translation:\n",
        "Translate from any language to any other language on the fly.\n",
        "Sentiment Analysis:\n",
        "Understand how your users feel so that you can cater to their taste better.\n",
        "Text summarization and keywork extraction:\n",
        "Understand the gist of what your users are saying immediately without having to read through everything yourself.\n",
        "\n",
        "\n",
        "OCR and Document Digitization:\n",
        "Digitization of document archives is an important step in the digital transformation of modern organizations. Cyshield offers optical character recognition (OCR) solutions for various languages to transform your documents into digital format.\n",
        "Our OCR solutions can handle:\n",
        "Noisy scans:\n",
        "With integrated image preprocessing, our system can clean up noisy and old documents to get accurate results.\n",
        "Complex fonts and scripts:\n",
        "Even if documents are written in a complex font, our system will be finetuned to get the best results for your documents.\n",
        "Sentiment Analysis:\n",
        "Understand how your users feel so that you can cater to their taste better.\n",
        "Complex layouts:\n",
        "No matter how your documents are laid out, our system will read every line and preserve the layout.\n",
        "Multiple Languages:\n",
        "Our system will read documents in almost any language, even bilingual documents.\n",
        "Ambiguous text:\n",
        "Our system will resolve ambiguous text and typos in your documents with an integrated text postprocessing system.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f464683c",
      "metadata": {
        "id": "f464683c"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Load needed API keys and relevant Python libraries.\n",
        "\n",
        "I will use this task:\n",
        "\n",
        "- [cohere](https://docs.cohere.com/) for embedding and answers generation.\n",
        "- [annoy](https://github.com/spotify/annoy) for building the vector database."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install --upgrade cohere\n",
        "!pip install annoy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzwbnnLKtvSm",
        "outputId": "e3bc5ca0-98ea-46eb-c6ec-38a671c5ec4b"
      },
      "id": "zzwbnnLKtvSm",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting boto3<2.0.0,>=1.34.0 (from cohere)\n",
            "  Downloading boto3-1.35.34-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx>=0.21.2 (from cohere)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.9.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.23.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Collecting sagemaker<3.0.0,>=2.232.1 (from cohere)\n",
            "  Downloading sagemaker-2.232.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.19.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20240914-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Collecting botocore<1.36.0,>=1.35.34 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading botocore-1.35.34-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.21.2->cohere)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.21.2->cohere)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Collecting attrs<24,>=23.1.0 (from sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (2.2.1)\n",
            "Collecting docker (from sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (0.2.0)\n",
            "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (4.23.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (2.2.2)\n",
            "Collecting pathos (from sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading pathos-0.3.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (4.3.6)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.12 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (5.9.5)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (6.0.2)\n",
            "Collecting sagemaker-core<2.0.0,>=1.0.0 (from sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading sagemaker_core-1.0.10-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting sagemaker-mlflow (from sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting schema (from sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: tblib<4,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (3.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (4.66.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.24.7)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.34->boto3<2.0.0,>=1.34.0->cohere) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker<3.0.0,>=2.232.1->cohere) (3.20.2)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere) (13.8.1)\n",
            "Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere) (0.20.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from google-pasta->sagemaker<3.0.0,>=2.232.1->cohere) (1.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker<3.0.0,>=2.232.1->cohere) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker<3.0.0,>=2.232.1->cohere) (2024.2)\n",
            "Collecting ppft>=1.7.6.9 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading ppft-1.7.6.9-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dill>=0.3.9 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pox>=0.3.5 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading pox-0.3.5-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting multiprocess>=0.70.17 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting mlflow>=2.8 (from sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading mlflow-2.16.2-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==2.16.2 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading mlflow_skinny-2.16.2-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (2.2.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting graphene<4 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.7.1)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (16.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (2.0.35)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.1.4)\n",
            "Collecting gunicorn<24 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (8.1.7)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading databricks_sdk-0.33.0-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.27.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.5.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere) (2.18.0)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (2.2.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting aniso8601<10,>=8 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (2.1.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (2.27.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.2.14)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.48b0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.16.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.6.1)\n",
            "Downloading cohere-5.11.0-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading boto3-1.35.34-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading sagemaker-2.232.2-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
            "Downloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\n",
            "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.34-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sagemaker_core-1.0.10-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.4/388.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathos-0.3.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\n",
            "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-2.16.2-py3-none-any.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.16.2-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Downloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pox-0.3.5-py3-none-any.whl (29 kB)\n",
            "Downloading ppft-1.7.6.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.33.0-py3-none-any.whl (562 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.0/563.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: schema, aniso8601, types-requests, smmap, smdebug-rulesconfig, ppft, pox, parameterized, mock, Mako, jmespath, importlib-metadata, httpx-sse, h11, gunicorn, graphql-core, fastavro, dill, attrs, multiprocess, httpcore, graphql-relay, gitdb, docker, botocore, alembic, s3transfer, pathos, httpx, graphene, gitpython, databricks-sdk, boto3, sagemaker-core, mlflow-skinny, mlflow, sagemaker-mlflow, sagemaker, cohere\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.4.0\n",
            "    Uninstalling importlib_metadata-8.4.0:\n",
            "      Successfully uninstalled importlib_metadata-8.4.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 24.2.0\n",
            "    Uninstalling attrs-24.2.0:\n",
            "      Successfully uninstalled attrs-24.2.0\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.3 aniso8601-9.0.1 attrs-23.2.0 boto3-1.35.34 botocore-1.35.34 cohere-5.11.0 databricks-sdk-0.33.0 dill-0.3.9 docker-7.1.0 fastavro-1.9.7 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.4 graphql-relay-3.2.0 gunicorn-23.0.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 httpx-sse-0.4.0 importlib-metadata-6.11.0 jmespath-1.0.1 mlflow-2.16.2 mlflow-skinny-2.16.2 mock-4.0.3 multiprocess-0.70.17 parameterized-0.9.0 pathos-0.3.3 pox-0.3.5 ppft-1.7.6.9 s3transfer-0.10.2 sagemaker-2.232.2 sagemaker-core-1.0.10 sagemaker-mlflow-0.1.0 schema-0.7.7 smdebug-rulesconfig-1.0.1 smmap-5.0.1 types-requests-2.32.0.20240914\n",
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp310-cp310-linux_x86_64.whl size=552449 sha256=1b20792796c622092f96dd11cbcf2d0c42f1fb8215ee4b45c8e31f7bf3e85775\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/8a/da/f714bcf46c5efdcfcac0559e63370c21abe961c48e3992465a\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5ad188a7-9b22-41cf-be13-9b9aa88b1d8b",
      "metadata": {
        "height": 64,
        "id": "5ad188a7-9b22-41cf-be13-9b9aa88b1d8b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4b8e6539",
      "metadata": {
        "height": 98,
        "id": "4b8e6539",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3235ef-547e-4614-ff73-6dc708401e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
            "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
          ]
        }
      ],
      "source": [
        "import cohere\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26b2d46b",
      "metadata": {
        "id": "26b2d46b"
      },
      "source": [
        "# Chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will chunk the article be paragraphs so each chunk will have solid info and meaning"
      ],
      "metadata": {
        "id": "ZwBnQMzICRCv"
      },
      "id": "ZwBnQMzICRCv"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6048a9ee-d489-437c-8dd6-38c228b59b06",
      "metadata": {
        "height": 98,
        "id": "6048a9ee-d489-437c-8dd6-38c228b59b06"
      },
      "outputs": [],
      "source": [
        "# Split into a list of paragraphs\n",
        "texts = article.split('\\n\\n')\n",
        "\n",
        "# Clean up to remove empty spaces and new lines\n",
        "texts = np.array([t.strip(' \\n') for t in texts if t])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1ce659d9-b665-4559-804e-509001ee39e7",
      "metadata": {
        "height": 30,
        "id": "1ce659d9-b665-4559-804e-509001ee39e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d04a726-3a97-40a8-918e-64e065a98d42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Statistical Modelling and Analysis:\\nAt Cyshield, AI is not just a buzzword for us! We know exactly how to realize the full potential of AI to support your business. Our data scientists will quickly build and fine-tune predictive analytics solutions to provide you with actionable insights to take your business to the next level.\\nWe will gladly take care of all the complicated infrastructure required to build and maintain AI models so that you can focus on what matters.',\n",
              "       'Big Data:\\nWith an ever-increasing amount of data being created every day, specialized big data platforms, pipelines and analysis technique are required to handle storage and analysis of such immense volumes of data.\\nCyshield big data services to efficiently acquire, transform, and analyze data. Our data scientists and engineers will help you make sense out of big data and provide you with valuable insights that can transform your business.'],\n",
              "      dtype='<U1019')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "texts[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "894c03da",
      "metadata": {
        "id": "894c03da"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can use embedding models from `sentence transformer` or `openai`, but here I will `Cohere` to [embed](https://docs.cohere.com/reference/embed) each chunk by the `embed-multilingual-v3.0` embedding model."
      ],
      "metadata": {
        "id": "WyfQJfvlDOMJ"
      },
      "id": "WyfQJfvlDOMJ"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c9d1086f-2713-41c5-9f60-049d25ad2b4b",
      "metadata": {
        "height": 132,
        "id": "c9d1086f-2713-41c5-9f60-049d25ad2b4b"
      },
      "outputs": [],
      "source": [
        "co = cohere.Client(os.environ['COHERE_API_KEY'])\n",
        "\n",
        "# Get the embeddings\n",
        "response = co.embed(\n",
        "    texts=texts.tolist(),\n",
        "    model='embed-multilingual-v3.0',\n",
        "    input_type='search_document'\n",
        ").embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38ef402c",
      "metadata": {
        "id": "38ef402c"
      },
      "source": [
        "# Build a search index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now instead of consuming/using an on-the-shelf `Vector database`, I will use `Annoy` to build an index that stores the embeddings in a way that is optimized for fast search. This approach scales well to a large number of texts (other options include [Faiss](https://github.com/facebookresearch/faiss), [ScaNN](https://github.com/google-research/google-research/tree/master/scann), and [PyNNDescent](https://github.com/lmcinnes/pynndescent)).\n",
        "\n",
        "After building the index, we can use it to retrieve the nearest neighbors either of existing questions, or of new questions that we embed."
      ],
      "metadata": {
        "id": "D7W_i9pQ8jZ6"
      },
      "id": "D7W_i9pQ8jZ6"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cc497e02-fa39-4357-a715-45df1e88e162",
      "metadata": {
        "height": 64,
        "id": "cc497e02-fa39-4357-a715-45df1e88e162"
      },
      "outputs": [],
      "source": [
        "from annoy import AnnoyIndex\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7a0a49d5-bfb7-4267-81f3-70df49d604be",
      "metadata": {
        "height": 200,
        "id": "7a0a49d5-bfb7-4267-81f3-70df49d604be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc653172-8512-429a-eddd-5a1005f264b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Check the dimensions of the embeddings\n",
        "embeds = np.array(response)\n",
        "\n",
        "# Create the search index, pass the size of embedding\n",
        "search_index = AnnoyIndex(embeds.shape[1], 'angular')\n",
        "# Add all the vectors to the search index\n",
        "for i in range(len(embeds)):\n",
        "    search_index.add_item(i, embeds[i])\n",
        "\n",
        "search_index.build(10) # 10 trees\n",
        "search_index.save('test.ann')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13876608",
      "metadata": {
        "id": "13876608"
      },
      "source": [
        "# Searching Articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c428f6ac-cf88-4914-9813-eefbad552a8d",
      "metadata": {
        "height": 217,
        "id": "c428f6ac-cf88-4914-9813-eefbad552a8d"
      },
      "outputs": [],
      "source": [
        "def search_cyshield_services(query):\n",
        "    # Get the query's embedding\n",
        "    query_embed = co.embed(texts=[query],\n",
        "                            model='embed-multilingual-v3.0',\n",
        "                            input_type='search_query').embeddings\n",
        "\n",
        "    # Retrieve the nearest neighbors\n",
        "    similar_item_ids = search_index.get_nns_by_vector(query_embed[0],\n",
        "                                                    10,\n",
        "                                                  include_distances=True)\n",
        "\n",
        "    search_results = texts[similar_item_ids[0]]\n",
        "\n",
        "    return search_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "fa6ce113-6444-4517-9bc4-03552a469a21",
      "metadata": {
        "height": 98,
        "id": "fa6ce113-6444-4517-9bc4-03552a469a21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166d378a-6697-4a02-bbc3-1c1e59fea6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computer Vision:\n",
            "With the prevalence of cameras and CCTV, computer vision techniques have become indispensable to extract information from visual data. At Cyshield, we build state-of-the-art deep learning models to detect and identify any relevant information from images and videos.\n",
            "Our computer vision applications include:\n",
            "Object detection:\n",
            "detect and identify objects of interest in images and videos.\n",
            "Facial Recognition:\n",
            "Recognize people and facial features in images and videos.\n",
            "Activity recognition:\n",
            "Recognize certain activities from video feeds.\n"
          ]
        }
      ],
      "source": [
        "results = search_cyshield_services(\n",
        "    \"what does cyshild do in CV?\"\n",
        ")\n",
        "\n",
        "print(results[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0fcf20a",
      "metadata": {
        "id": "f0fcf20a"
      },
      "source": [
        "# Generating Answers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now here I will use the `command-r-plus` model from Cohere for generation which is the latest and rapidly updated"
      ],
      "metadata": {
        "id": "-XsFX-mDGCee"
      },
      "id": "-XsFX-mDGCee"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c63a5f76-d54d-46f3-ac04-1213031ab6e7",
      "metadata": {
        "height": 489,
        "id": "c63a5f76-d54d-46f3-ac04-1213031ab6e7"
      },
      "outputs": [],
      "source": [
        "def ask_cyshield_services(question, num_generations=1):\n",
        "\n",
        "    # Search the text archive\n",
        "    results = search_cyshield_services(question)\n",
        "\n",
        "    # Get the top result\n",
        "    context = results[0]\n",
        "\n",
        "    # Prepare the prompt\n",
        "    prompt = f\"\"\"\n",
        "    Excerpt from the article titled \"Cyshield AI & DS services\":\n",
        "    {context}\n",
        "    Question: {question}\n",
        "\n",
        "    Extract the answer of the question from the text provided.\n",
        "    And Must the answer be in the same language as the question given.\n",
        "    If the text doesn't contain the answer,\n",
        "    reply that the answer is not available.\"\"\"\n",
        "\n",
        "    prediction = co.generate(\n",
        "        prompt=prompt,\n",
        "        max_tokens=100,\n",
        "        model=\"command-r-plus\",\n",
        "        temperature=0.3,\n",
        "        num_generations=num_generations\n",
        "    )\n",
        "\n",
        "    return prediction.generations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "20b4f4c6-dc1a-4837-a131-4c3d13d6d4c5",
      "metadata": {
        "height": 115,
        "id": "20b4f4c6-dc1a-4837-a131-4c3d13d6d4c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9245bcbc-5210-4c84-dabb-eaccc0eb1a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, Cyshield offers optical character recognition (OCR) solutions as part of its AI and DS services.\n"
          ]
        }
      ],
      "source": [
        "results = ask_cyshield_services(\n",
        "    \"Does Cyshield provide any thing related to the optical character recognition?\",\n",
        ")\n",
        "\n",
        "print(results[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "6d2f03ac-2e99-4442-a386-db9163c784db",
      "metadata": {
        "height": 30,
        "id": "6d2f03ac-2e99-4442-a386-db9163c784db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbd111f-ddff-42de-c154-6d3b5b0984a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تقدم شركة Cyshield حلول NLP المتقدمة في العديد من اللغات للتطبيقات التالية: chatbots، والترجمة الآلية، وتحليل المشاعر، وملخص النص واستخراج الكلمات الرئيسية.\n"
          ]
        }
      ],
      "source": [
        "results = ask_cyshield_services(\n",
        "    \"ماذا تفعل سايشيلد في معالجة اللغة الطبيعية؟\",\n",
        ")\n",
        "\n",
        "print(results[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "9c65f0a8-a601-4029-a79e-b0005b9d3958",
      "metadata": {
        "height": 30,
        "id": "9c65f0a8-a601-4029-a79e-b0005b9d3958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5026ae7-8c00-4112-891b-840ef462737e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The answer is not available.\n"
          ]
        }
      ],
      "source": [
        "results = ask_cyshield_services(\n",
        "    \"does Cyshield offers some meals ?\",\n",
        ")\n",
        "\n",
        "print(results[0].text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}